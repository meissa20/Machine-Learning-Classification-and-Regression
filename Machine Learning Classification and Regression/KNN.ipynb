{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605890fc-41ef-4dd6-bed7-00276a68f85a",
   "metadata": {},
   "source": [
    "### we will use:\n",
    "##### Pandas\n",
    "- load and preprocess the dataset\n",
    "##### sklearn\n",
    "-  split the data into training testing and cross validation sets\n",
    "-  Train the KNN classifier\n",
    "-  Evaluate the model using accuracy, precision, recall, and F1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69c52d3b-51a2-4b66-a17d-9afe643198b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c614c171-68f8-43a8-9dbf-51d774500562",
   "metadata": {},
   "source": [
    "Define column names for the dataset since."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bba2d6a8-6b68-4f3f-a1d2-d4678673a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"I1\", \"I2\", \"I3\", \"I4\", \"I5\", \"I6\", \"I7\",\"I8\", \"I9\", \"I10\", \"o1\"]\n",
    "df = pd.read_csv(\"magic04.data\", names = column_names)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a01605-48ed-4835-914d-2e10dbe35c42",
   "metadata": {},
   "source": [
    "Downsample the gamma class to match the number of hadron samples to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6a3b499-7fac-4587-bd4e-774826be8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_df = df[df[\"o1\"] == \"g\"]\n",
    "hadron_df = df[df[\"o1\"] == \"h\"]\n",
    "gamma_df = gamma_df.sample(n=len(hadron_df), random_state=42)\n",
    "balanced_df = pd.concat([gamma_df, hadron_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137662a5-3ddd-4441-80cd-037e2b1da58f",
   "metadata": {},
   "source": [
    "Split dataset randomly so that the training set would form 70% of the validation set 15%\n",
    "and 15% for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "608c06f7-65c4-41ad-89e6-c5979faa4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_df.drop(columns=[\"o1\"])\n",
    "Y = balanced_df[\"o1\"]\n",
    "x_train, x_, y_train,y_ = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "x_cv, x_test, y_cv,y_test = train_test_split(x_, y_, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c409a1-d0e4-43cc-8ec4-c91683620fdb",
   "metadata": {},
   "source": [
    "Iterate over k values from 1 to 20 to find the optimal number of neighbors for KNN.\n",
    "\n",
    "Train a KNN classifier with the current k value using KNN classifier from sklearn library.\n",
    "\n",
    "Predict labels for the cross-validation set and calculate evaluation metrics (accuracy, precision, recall, F1-score).\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Confusion Matrix} =\n",
    "\\begin{bmatrix}\n",
    "TP & FN \\\\\n",
    "FP & TN\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9945602c-3928-490c-b5f9-06b44a458286",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for k in range(1, 21):\n",
    "    eval = KNeighborsClassifier(n_neighbors=k)\n",
    "    eval.fit(x_train,y_train)\n",
    "    y_pred = eval.predict(x_cv)\n",
    "    \n",
    "    accuracy = accuracy_score(y_cv, y_pred)\n",
    "    precision = precision_score(y_cv, y_pred, pos_label='g')\n",
    "    recall = recall_score(y_cv, y_pred, pos_label='g')\n",
    "    f1 = f1_score(y_cv, y_pred, pos_label='g')\n",
    "    cm = confusion_matrix(y_cv, y_pred, labels=['g','h'])\n",
    "    \n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'eval model': eval\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da409e0-2c40-46f6-a6c5-48e04e4ef72a",
   "metadata": {},
   "source": [
    "Report all of the trained model accuracy, precision, recall and f-score as well as confusion\n",
    "matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8dc8cc5d-afe9-462c-940c-98f13b907705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Accuracy: 0.7383\n",
      "Precision: 0.7236\n",
      "Recall: 0.7957\n",
      "F1-Score: 0.7580\n",
      "Confusion Matrix:\n",
      "[[822 211]\n",
      " [314 659]]\n",
      "\n",
      "\n",
      "k = 2\n",
      "Accuracy: 0.7433\n",
      "Precision: 0.6874\n",
      "Recall: 0.9197\n",
      "F1-Score: 0.7867\n",
      "Confusion Matrix:\n",
      "[[950  83]\n",
      " [432 541]]\n",
      "\n",
      "\n",
      "k = 3\n",
      "Accuracy: 0.7657\n",
      "Precision: 0.7425\n",
      "Recall: 0.8345\n",
      "F1-Score: 0.7858\n",
      "Confusion Matrix:\n",
      "[[862 171]\n",
      " [299 674]]\n",
      "\n",
      "\n",
      "k = 4\n",
      "Accuracy: 0.7537\n",
      "Precision: 0.7062\n",
      "Recall: 0.8935\n",
      "F1-Score: 0.7889\n",
      "Confusion Matrix:\n",
      "[[923 110]\n",
      " [384 589]]\n",
      "\n",
      "\n",
      "k = 5\n",
      "Accuracy: 0.7697\n",
      "Precision: 0.7422\n",
      "Recall: 0.8470\n",
      "F1-Score: 0.7911\n",
      "Confusion Matrix:\n",
      "[[875 158]\n",
      " [304 669]]\n",
      "\n",
      "\n",
      "k = 6\n",
      "Accuracy: 0.7627\n",
      "Precision: 0.7167\n",
      "Recall: 0.8916\n",
      "F1-Score: 0.7947\n",
      "Confusion Matrix:\n",
      "[[921 112]\n",
      " [364 609]]\n",
      "\n",
      "\n",
      "k = 7\n",
      "Accuracy: 0.7747\n",
      "Precision: 0.7485\n",
      "Recall: 0.8470\n",
      "F1-Score: 0.7947\n",
      "Confusion Matrix:\n",
      "[[875 158]\n",
      " [294 679]]\n",
      "\n",
      "\n",
      "k = 8\n",
      "Accuracy: 0.7682\n",
      "Precision: 0.7243\n",
      "Recall: 0.8877\n",
      "F1-Score: 0.7977\n",
      "Confusion Matrix:\n",
      "[[917 116]\n",
      " [349 624]]\n",
      "\n",
      "\n",
      "k = 9\n",
      "Accuracy: 0.7702\n",
      "Precision: 0.7416\n",
      "Recall: 0.8500\n",
      "F1-Score: 0.7921\n",
      "Confusion Matrix:\n",
      "[[878 155]\n",
      " [306 667]]\n",
      "\n",
      "\n",
      "k = 10\n",
      "Accuracy: 0.7747\n",
      "Precision: 0.7311\n",
      "Recall: 0.8896\n",
      "F1-Score: 0.8026\n",
      "Confusion Matrix:\n",
      "[[919 114]\n",
      " [338 635]]\n",
      "\n",
      "\n",
      "k = 11\n",
      "Accuracy: 0.7717\n",
      "Precision: 0.7406\n",
      "Recall: 0.8567\n",
      "F1-Score: 0.7944\n",
      "Confusion Matrix:\n",
      "[[885 148]\n",
      " [310 663]]\n",
      "\n",
      "\n",
      "k = 12\n",
      "Accuracy: 0.7707\n",
      "Precision: 0.7268\n",
      "Recall: 0.8887\n",
      "F1-Score: 0.7997\n",
      "Confusion Matrix:\n",
      "[[918 115]\n",
      " [345 628]]\n",
      "\n",
      "\n",
      "k = 13\n",
      "Accuracy: 0.7752\n",
      "Precision: 0.7421\n",
      "Recall: 0.8635\n",
      "F1-Score: 0.7982\n",
      "Confusion Matrix:\n",
      "[[892 141]\n",
      " [310 663]]\n",
      "\n",
      "\n",
      "k = 14\n",
      "Accuracy: 0.7712\n",
      "Precision: 0.7289\n",
      "Recall: 0.8848\n",
      "F1-Score: 0.7993\n",
      "Confusion Matrix:\n",
      "[[914 119]\n",
      " [340 633]]\n",
      "\n",
      "\n",
      "k = 15\n",
      "Accuracy: 0.7747\n",
      "Precision: 0.7399\n",
      "Recall: 0.8674\n",
      "F1-Score: 0.7986\n",
      "Confusion Matrix:\n",
      "[[896 137]\n",
      " [315 658]]\n",
      "\n",
      "\n",
      "k = 16\n",
      "Accuracy: 0.7747\n",
      "Precision: 0.7296\n",
      "Recall: 0.8935\n",
      "F1-Score: 0.8033\n",
      "Confusion Matrix:\n",
      "[[923 110]\n",
      " [342 631]]\n",
      "\n",
      "\n",
      "k = 17\n",
      "Accuracy: 0.7772\n",
      "Precision: 0.7394\n",
      "Recall: 0.8761\n",
      "F1-Score: 0.8019\n",
      "Confusion Matrix:\n",
      "[[905 128]\n",
      " [319 654]]\n",
      "\n",
      "\n",
      "k = 18\n",
      "Accuracy: 0.7707\n",
      "Precision: 0.7258\n",
      "Recall: 0.8916\n",
      "F1-Score: 0.8002\n",
      "Confusion Matrix:\n",
      "[[921 112]\n",
      " [348 625]]\n",
      "\n",
      "\n",
      "k = 19\n",
      "Accuracy: 0.7732\n",
      "Precision: 0.7346\n",
      "Recall: 0.8761\n",
      "F1-Score: 0.7991\n",
      "Confusion Matrix:\n",
      "[[905 128]\n",
      " [327 646]]\n",
      "\n",
      "\n",
      "k = 20\n",
      "Accuracy: 0.7677\n",
      "Precision: 0.7227\n",
      "Recall: 0.8906\n",
      "F1-Score: 0.7979\n",
      "Confusion Matrix:\n",
      "[[920 113]\n",
      " [353 620]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f\"k = {result['k']}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['precision']:.4f}\")\n",
    "    print(f\"Recall: {result['recall']:.4f}\")\n",
    "    print(f\"F1-Score: {result['f1_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['confusion_matrix'])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08f7b7-66fa-44c8-8ceb-a5d7af08afee",
   "metadata": {},
   "source": [
    "Select the model with the highest F1-score from the validation results.\n",
    "\n",
    "Retrieve the best-trained KNN model and use it for final evaluation on the test set.\n",
    "\n",
    "Predict labels for the test set and compute evaluation metrics (accuracy, precision, recall, F1-score).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "850867e7-db8a-4fc2-a912-e6a84868ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = max(results, key=lambda x: x['f1_score'])\n",
    "eval = best_result['eval model']\n",
    "y_pred = eval.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred, pos_label='g')\n",
    "test_recall = recall_score(y_test, y_pred, pos_label='g')\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label='g')\n",
    "test_cm = confusion_matrix(y_test, y_pred, labels=['g','h'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d6dcc-c0dc-4811-a552-8255ea1669e7",
   "metadata": {},
   "source": [
    "Display the best value of k (number of neighbors) that resulted in the highest F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f7acefe-5bc7-4125-bf1e-afe858670a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k = 16\n",
      "Test accuracy: 0.7539\n",
      "Test recision: 0.6969\n",
      "Test recall: 0.8740\n",
      "Test F1-Score: 0.7755\n",
      "Test Confusion Matrix:\n",
      "[[853 123]\n",
      " [371 660]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"best k = {best_result['k']}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test recision: {test_precision:.4f}\")\n",
    "print(f\"Test recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(test_cm)\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
